# ===================================
# LLM Commerce - Environment Variables
# ===================================

# ----- LLM Provider Configuration -----

# Option 1: OpenAI (Cloud)
OPENAI_API_KEY=sk-your-api-key-here

# Option 2: Ollama (Local)
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=llama3.1

# Which provider to use: "openai" or "ollama"
LLM_PROVIDER=openai

# ----- Database Configuration -----

# SQLite (default - no configuration needed)
DATABASE_URL=sqlite:///./data/llm_commerce.db

# PostgreSQL (alternative)
# DATABASE_URL=postgresql://user:password@localhost:5432/llm_commerce

# ----- Vector Store Configuration -----

# ChromaDB (default)
CHROMA_PERSIST_DIRECTORY=./data/chroma
CHROMA_COLLECTION_NAME=products

# pgvector (alternative - requires PostgreSQL)
# PGVECTOR_CONNECTION=postgresql://user:password@localhost:5432/llm_commerce

# ----- Server Configuration -----

# Backend
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000

# Frontend
VITE_API_URL=http://localhost:8000

# ----- Security -----

# Session secret (generate with: openssl rand -hex 32)
SESSION_SECRET=your-secret-key-here

# CORS allowed origins (comma separated)
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# ----- Optional Features -----

# Enable analytics
ENABLE_ANALYTICS=false

# Enable debug logging
DEBUG=true

# Rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=30

# ----- LLM Configuration -----

# Model settings
LLM_MODEL=gpt-3.5-turbo
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500

# Embedding model
EMBEDDING_MODEL=text-embedding-3-small

# ----- Redis (optional - for production) -----

# REDIS_URL=redis://localhost:6379

# ----- Deployment (optional) -----

# Environment: development | production
ENV=development

# Sentry (error tracking)
# SENTRY_DSN=your-sentry-dsn

# ----- OpenAI Cost Tracking -----

# Log token usage
LOG_TOKEN_USAGE=true
